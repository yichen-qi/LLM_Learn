{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794386bf",
   "metadata": {},
   "source": [
    "# 模型微调概念和流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4f544",
   "metadata": {},
   "source": [
    "## 制作Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a5560f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n",
      "('选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 1)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.dataset = load_from_disk('/home/yichen/LLM_Learn/data/lansinuote/chn_senti_corp_dataset')\n",
    "\n",
    "        if split == 'train':\n",
    "            self.data = self.dataset['train']\n",
    "        elif split == 'validation':\n",
    "            self.data = self.dataset['validation']\n",
    "        elif split == 'test':\n",
    "            self.data = self.dataset['test']\n",
    "        else:\n",
    "            raise ValueError('Invalid split')\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]['text'], self.data[item]['label']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dataset = CustomDataset('train')\n",
    "    print(len(train_dataset))\n",
    "    print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd486eb",
   "metadata": {},
   "source": [
    "## 下游任务模型设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603924ed",
   "metadata": {},
   "source": [
    "### 加载预训练模型\n",
    "\n",
    "查看模型的输入和输出尺寸\n",
    "```bash\n",
    "BertModel(\n",
    "  (embeddings): BertEmbeddings(\n",
    "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
    "    ........\n",
    "(pooler): BertPooler(\n",
    "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "    ......\n",
    "```\n",
    "`\n",
    "输入部分的词嵌入层的输入维度是21128，即BERT模型的词表大小，输出维度是768，即BERT模型的embedding size。\n",
    "\n",
    "输出部分的pooler层的输入维度是768，输出维度是768，即BERT模型的embedding size。\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ed477f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_dir = \"./model/google-bert/bert-base-chinese/models--google-bert--bert-base-chinese/snapshots/c30a6ed22ab4564dc1e3b2ecbf6e766b0611a33f\"\n",
    "\n",
    "bert_model = BertModel.from_pretrained(model_dir)\n",
    "#if cuda is available, move the model to cuda\n",
    "# model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a2e5b",
   "metadata": {},
   "source": [
    "### 定义下游任务模型(将主干网络提取的特征进行分类)\n",
    "`注意上游任务不参与训练`\n",
    "\n",
    "```python\n",
    "def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "```\n",
    "```\n",
    "参数名                   说明                       \n",
    "----------------------  --------------------------  ------------------------------------------------------\n",
    "input_ids                每个 token 的 ID，表示输入文本\n",
    "\n",
    "attention_mask           标记哪些位置是有效的（1）或 padding（0）\n",
    "\n",
    "token_type_ids           区分第一个句子和第二个句子（对于句对任 务），单句时全 0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cc2de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        #上游不参与训练\n",
    "        with torch.no_grad():\n",
    "            out = bert_model(input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids)\n",
    "\n",
    "        #下游参与训练\n",
    "\n",
    "        out = self.fc(out.last_hidden_state[:,0])\n",
    "        out = out.softmax(dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9041f5f",
   "metadata": {},
   "source": [
    "### 自定义模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 100\n",
    "\n",
    "model_dir = \"./model/google-bert/bert-base-chinese/models--google-bert--bert-base-chinese/snapshots/c30a6ed22ab4564dc1e3b2ecbf6e766b0611a33f\"\n",
    "\n",
    "token = BertTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "#数据编码处理\n",
    "def collate_fn(data):\n",
    "    sentences = [item[0] for item in data]\n",
    "    labels = [item[1] for item in data]\n",
    "\n",
    "    data = token.batch_encode_plus(\n",
    "        sentences,\n",
    "        padding=\"max_length\",\n",
    "        max_length=350,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_length=True\n",
    "    )\n",
    "    input_ids = data[\"input_ids\"]\n",
    "    attention_mask = data[\"attention_mask\"]\n",
    "    token_type_ids = data[\"token_type_ids\"]\n",
    "    labels = torch.LongTensor(labels)\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset('train')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(device)\n",
    "    my_model = Model() #if use cuda my_model = Model().to(device)\n",
    "\n",
    "    optimizer = AdamW(my_model.parameters(), lr=5e-4)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    my_model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_loader):\n",
    "            input_ids = input_ids # if use cuda input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask\n",
    "            token_type_ids = token_type_ids\n",
    "            labels = labels\n",
    "\n",
    "            out = my_model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "            loss = loss_func(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                out = out.argmax(dim=1)\n",
    "                acc = (out == labels).sum().item() / len(labels)\n",
    "                print(f\"Epoch: {epoch}, Step: {step}, Loss: {loss.item()}, Acc: {acc}\")\n",
    "\n",
    "        torch.save(my_model.state_dict(), f\"params/{epoch}bert.pt\")\n",
    "        print(f\"Epoch: {epoch}, Save model params\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e12477",
   "metadata": {},
   "source": [
    "## 模型性能测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_dir = \"./model/google-bert/bert-base-chinese/models--google-bert--bert-base-chinese/snapshots/c30a6ed22ab4564dc1e3b2ecbf6e766b0611a33f\"\n",
    "\n",
    "token = BertTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "def collate_fn(data):\n",
    "    sentences = [item[0] for item in data]\n",
    "    labels = [item[1] for item in data]\n",
    "\n",
    "    data = token.batch_encode_plus(\n",
    "        sentences,\n",
    "        padding=\"max_length\",\n",
    "        max_length=350,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_length=True\n",
    "    )\n",
    "    input_ids = data[\"input_ids\"]\n",
    "    attention_mask = data[\"attention_mask\"]\n",
    "    token_type_ids = data[\"token_type_ids\"]\n",
    "    labels = torch.LongTensor(labels)\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "    \n",
    "test_dataset = CustomDataset('test')\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    acc = 0\n",
    "    total = 0\n",
    "\n",
    "    test_model = Model()\n",
    "    test_model.load_state_dict(torch.load('params/2bert.pt'))\n",
    "    test_model.eval()\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(test_loader):\n",
    "        input_ids = input_ids\n",
    "        attention_mask = attention_mask\n",
    "        token_type_ids = token_type_ids\n",
    "        labels = labels\n",
    "        # input_ids = input_ids.to(device)\n",
    "        # attention_mask = attention_mask.to(device)\n",
    "        # token_type_ids = token_type_ids.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        out = test_model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        out = out.argmax(dim=1)\n",
    "        acc += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "    print(\"Test Accuracy: {:.4f}\".format(acc/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b29d58",
   "metadata": {},
   "source": [
    "## 模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fdc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_dir = \"./model/google-bert/bert-base-chinese/models--google-bert--bert-base-chinese/snapshots/c30a6ed22ab4564dc1e3b2ecbf6e766b0611a33f\"\n",
    "\n",
    "token = BertTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "trained_model = Model()\n",
    "\n",
    "names = [\"负向评价\", \"正向评价\"]\n",
    "\n",
    "def collate_fn(data):\n",
    "    sentences = []\n",
    "    sentences.append(data)\n",
    "    \n",
    "\n",
    "    data = token.batch_encode_plus(\n",
    "        sentences,\n",
    "        padding=\"max_length\",\n",
    "        max_length=350,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_length=True\n",
    "    )\n",
    "\n",
    "    input_ids = data[\"input_ids\"]\n",
    "    attention_mask = data[\"attention_mask\"]\n",
    "    token_type_ids = data[\"token_type_ids\"]\n",
    "    return input_ids, attention_mask, token_type_ids\n",
    "\n",
    "def test():\n",
    "    trained_model.load_state_dict(torch.load('params/2bert.pt'))\n",
    "    trained_model.eval()\n",
    "\n",
    "    while True:\n",
    "        sentence = input(\"请输入句子(输入q退出)：\")\n",
    "        if sentence == \"q\":\n",
    "            print(\"退出\")\n",
    "            break\n",
    "        \n",
    "        input_ids, attention_mask, token_type_ids = collate_fn([sentence])\n",
    "        # input_ids = input_ids.to(device)\n",
    "        # attention_mask = attention_mask.to(device)\n",
    "        # token_type_ids = token_type_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = trained_model(input_ids, attention_mask, token_type_ids)\n",
    "            output = output.argmax(dim=1)\n",
    "            print(\"模型判定\", names[output], \"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
